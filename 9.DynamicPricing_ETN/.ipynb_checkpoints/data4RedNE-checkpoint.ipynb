{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be39dce3-a988-4d84-b957-7d08b456677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from src.dynamic_pricing_data_loader import cargar_y_preparar_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918f010-a023-4423-aaf6-73abc214140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data():\n",
    "    # Obtener el directorio de trabajo actual (ruta principal del proyecto).\n",
    "    ruta_principal = os.getcwd()\n",
    "\n",
    "    # Construir la ruta al archivo de configuración \"config/config.json\".\n",
    "    config_path = os.path.join(ruta_principal, \"config\", \"config.json\")\n",
    "\n",
    "    # Llamar a la función externa que carga y realiza preprocesamiento inicial.\n",
    "    Frame = cargar_y_preparar_datos(config_path, ruta_principal)\n",
    "\n",
    "    # Seleccionar solo las columnas relevantes para el análisis.\n",
    "    Frame = Frame[[\"FECHA_CORRIDA\", \"HORA_SALIDA_CORRIDA\", \"CLASE_SERVICIO\", 'IVA_TARIFA_BASE_TRAMO',\n",
    "    \"PAX_SUBEN\", \"TARIFA_BASE_TRAMO\",'FECHA_OPERACION', 'HORA_OPERACION','VENTA','DISPONIBILIDAD_TRAMO',\n",
    "    'HORAS_ANTICIPACION','ORIGEN', 'DESTINO','TIPO_CLIENTE','NUM_ASIENTO'\n",
    "                  ]].copy()\n",
    "\n",
    "    return Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1137283-c09b-4e15-b3fa-fba8d97b95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prepare_Data(df):\n",
    "    #df=Get_Data()\n",
    "    # Se filtra el DataFrame para incluir solo ventas mayores que cero.\n",
    "    df = df[df['VENTA'] > 0]\n",
    "    df['FECHA_OPERACION'] = pd.to_datetime(df['FECHA_OPERACION'])\n",
    "    fecha_maxima = df['FECHA_OPERACION'].max()\n",
    "    df = df[df['FECHA_OPERACION'] < fecha_maxima].copy()\n",
    "    df['FECHA_CORRIDA'] = pd.to_datetime(df['FECHA_CORRIDA'])\n",
    "    \n",
    "    df[\"HORA_SALIDA_CORRIDA\"] = pd.to_datetime(df[\"HORA_SALIDA_CORRIDA\"])\n",
    "    \n",
    "    df['TBT']= df['TARIFA_BASE_TRAMO']-df['IVA_TARIFA_BASE_TRAMO']\n",
    "    df['%_dif_TBT_Venta']= (df['TBT']-df['VENTA'])/df['TBT']\n",
    "    df['TIPO_CLASE'] = np.where(\n",
    "        df['CLASE_SERVICIO'].astype(str).str.contains('DOS PISOS', case=False, na=False),\n",
    "        'DOS',\n",
    "        'UNO'\n",
    "    )\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54de7cd-c434-4ce2-9d97-d4f3be36020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data4RedNeuronal(df_1):\n",
    "    df=Prepare_Data(df_1)\n",
    "    df_total= pd.DataFrame()\n",
    "    df_total['Origen-Destino'] = df['ORIGEN'].astype(str) + '-' + df['DESTINO'].astype(str)\n",
    "    df_total['DiaSemana_Corrida']=df['FECHA_CORRIDA'].dt.dayofweek\n",
    "    df_total['Hora_Corrida']=df['HORA_SALIDA_CORRIDA'].dt.hour\n",
    "    df_total[['NUM_ASIENTO','HORAS_ANTICIPACION','%_dif_TBT_Venta']]=df[['NUM_ASIENTO','HORAS_ANTICIPACION','%_dif_TBT_Venta']].copy()\n",
    "    df_total['Mes_Corrida']=df['FECHA_CORRIDA'].dt.month\n",
    "    df_total['Año_Corrida']=df['FECHA_CORRIDA'].dt.year\n",
    "    df_total['Buen_Dia'] = df['FECHA_CORRIDA'].dt.dayofweek.isin([4,5,6,0]).astype(int)\n",
    "    df_total['Buena_Hora'] = df['HORA_SALIDA_CORRIDA'].dt.hour.isin([23,17,18,19,20]).astype(int)\n",
    "    df_total['Buen_Mes'] = df['FECHA_CORRIDA'].dt.month.isin([3,4,5,6]).astype(int)\n",
    "    df_total['Buen_Asiento'] = df['NUM_ASIENTO'].isin([1,2,3,4,5,6,7,8,9,10]).astype(int)\n",
    "    # Crea un nuevo DataFrame con las variables dummy (codificación one-hot)\n",
    "    df_dummies = pd.get_dummies(\n",
    "        df['TIPO_CLIENTE'],\n",
    "        prefix='TIPO_CLIENTE', # Prefijo para las nuevas columnas (ej: TIPO_CLIENTE_A)\n",
    "        drop_first=False        # Elimina la primera categoría para evitar multicolinealidad\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Crea un nuevo DataFrame con las variables dummy (codificación one-hot)\n",
    "    df_dummies1 = pd.get_dummies(\n",
    "        df['TIPO_CLASE'],\n",
    "        prefix='PISO', \n",
    "        drop_first=False\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Une las nuevas columnas dummy al DataFrame original\n",
    "    df_total = pd.concat([df_total, df_dummies,df_dummies1], axis=1)\n",
    "    df_total['VENTA']=df['VENTA'].copy()\n",
    "\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9fb105-655d-470e-95c8-9f18d1880abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame=Get_Data()\n",
    "FrameN=Data4RedNeuronal(Frame.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075603af-8144-4b4d-a0d5-207a0a459168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FrameN.to_excel('PruebaData4RedN.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf00c2-12b1-4e2c-ac60-f464b1e50de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFlag(datos):\n",
    "\n",
    "    asimetria_pandas = datos.skew()\n",
    "    print(f\"Coeficiente de Asimetría: {asimetria_pandas:.4f}\")\n",
    "    \n",
    "    if asimetria_pandas > 1.0:\n",
    "        print(\"La asimetría es alta (> 1.0). La transformación logarítmica es altamente recomendable.\")\n",
    "        Bandera=True\n",
    "    elif asimetria_pandas > 0.5:\n",
    "        print(\"La asimetría es moderada (> 0.5). La transformación logarítmica podría ser beneficiosa.\")\n",
    "        Bandera=True\n",
    "    else:\n",
    "        print(\"La asimetría es baja. Una transformación no es necesaria.\")\n",
    "        Bandera=False\n",
    "        \n",
    "    return Bandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355d203-e6a0-4724-a6d9-37492803a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"datos=FrameN['VENTA']\n",
    "plt.hist(datos, bins=10, edgecolor='black')\n",
    "\n",
    "# 3. Añadir etiquetas y título\n",
    "plt.title('Histograma Básico con Matplotlib')\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# 4. Mostrar el gráfico\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6c4a7-7c88-482e-bd25-2bc80a166acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plt.hist(Y_log, bins=10, edgecolor='black')\n",
    "\n",
    "# 3. Añadir etiquetas y título\n",
    "plt.title('Histograma Básico con Matplotlib')\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "# 4. Mostrar el gráfico\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472247e5-b81c-4c4c-b9f8-4ed53164b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainingForm(df,Bandera):\n",
    "    # Definir la variable objetivo (Y)\n",
    "    Y = df['VENTA']\n",
    "    \n",
    "    if Bandera:\n",
    "        # Aplicar la transformación logarítmica a Y\n",
    "        Y_log = np.log(Y)\n",
    "    else:\n",
    "        Y_log = Y.copy()\n",
    "    \n",
    "    # Eliminar la variable VENTA del dataframe de features (X)\n",
    "    X = df.drop('VENTA', axis=1) \n",
    "    \n",
    "    categorical_features= 'Origen-Destino'\n",
    "    df_ohe = pd.get_dummies(X[categorical_features]).astype(int)\n",
    "    \n",
    "    # Columnas numéricas que necesitan Estandarización\n",
    "    # Excluimos las binarias/dummies que ya están bien escaladas (0 o 1)\n",
    "    numeric_features = [\n",
    "        'DiaSemana_Corrida', 'Hora_Corrida', 'NUM_ASIENTO', \n",
    "        'HORAS_ANTICIPACION', '%_dif_TBT_Venta', 'Mes_Corrida','Año_Corrida'\n",
    "    ]\n",
    "    \n",
    "    # Columnas binarias (se dejan pasar sin transformación)\n",
    "    binary_features = [col for col in X.columns if col not in [categorical_features] + numeric_features]\n",
    "    \n",
    "    indice_correcto = X[numeric_features].index # o df_ohe.index\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    # 2. Convierte el array escalado (NumPy) a DataFrame, ASIGNANDO el índice correcto\n",
    "    X_escalado_array = scaler.fit_transform(X[numeric_features])\n",
    "    X_escalado = pd.DataFrame(X_escalado_array, \n",
    "                              index=indice_correcto, # <-- ¡CLAVE!\n",
    "                              columns=numeric_features)\n",
    "    \n",
    "    X_processed= pd.concat([df_ohe, X_escalado,X[binary_features]], axis=1)\n",
    "\n",
    "    return X_processed, Y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3c514-12ce-421e-8b16-09f4ef802bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainingNet(X_processed,Y_log):\n",
    "    # División del 80% para entrenamiento y 20% para prueba\n",
    "    X_train, X_test, Y_train_log, Y_test_log = train_test_split(\n",
    "        X_processed, \n",
    "        Y_log, \n",
    "        test_size=0.2, \n",
    "        random_state=42 # Para asegurar resultados reproducibles\n",
    "    )\n",
    "    \n",
    "    input_feature_count = X_train.shape[1] \n",
    "    \n",
    "    print(f\"\\n--- Resumen de la División ---\")\n",
    "    print(f\"Número total de features (columnas) para la red neuronal: {input_feature_count}\")\n",
    "    print(f\"Tamaño de X_train (Entrenamiento): {X_train.shape}\")\n",
    "    print(f\"Tamaño de X_test (Prueba): {X_test.shape}\")\n",
    "    print(f\"Tamaño de Y_train_log (Objetivo de Entrenamiento): {Y_train_log.shape}\")\n",
    "    \n",
    "    # --- 1. Definir el número de features de entrada ---\n",
    "    # (Esto debe ser el número de columnas de tu X_train después del OHE y estandarización)\n",
    "    input_shape = X_train.shape[1] \n",
    "    \n",
    "    # --- 2. CONSTRUCCIÓN DEL MODELO ---\n",
    "    model = Sequential([\n",
    "        # Capa Oculta 1\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        \n",
    "        # Capa Oculta 2 (Regularización para evitar overfitting)\n",
    "        # Aquí puedes añadir 'Dropout' si notas que el modelo se sobreajusta\n",
    "        Dense(64, activation='relu'), \n",
    "        \n",
    "        # Capa de Salida: 1 neurona y activación lineal para regresión\n",
    "        Dense(1, activation='linear') \n",
    "    ])\n",
    "    \n",
    "    # --- 3. COMPILACIÓN DEL MODELO ---\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',           # Función de pérdida: Error Cuadrático Medio\n",
    "        metrics=['mae', 'mse']  # Métricas a monitorear: MAE y MSE\n",
    "    )\n",
    "    \n",
    "    # --- 4. ENTRENAMIENTO (Ejemplo) ---\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        Y_train_log,  # ¡Usamos la variable VENTA transformada con logaritmo!\n",
    "        epochs=10, \n",
    "        batch_size=32, \n",
    "        validation_split=0.2, # Usamos el 20% para validación interna\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    PredictingNet(model,X_test, Y_test_log)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6dd68-c405-49ee-bc06-ed56e105d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictingNet(model,X_test, Y_test_log):\n",
    "    # 'model' es tu red neuronal entrenada\n",
    "    # 'X_test' son tus features de prueba (escalados y codificados)\n",
    "    Y_pred_log = model.predict(X_test)\n",
    "    \n",
    "    if Bandera:\n",
    "        # Revertir la predicción logarítmica a la escala de precio real\n",
    "        Y_pred_real = np.exp(Y_pred_log)\n",
    "        # Revertir los valores reales de prueba (Y_test_log) a la escala de precio real\n",
    "        # Esto es para compararlos directamente\n",
    "        Y_test_real = np.exp(Y_test_log) \n",
    "    else:\n",
    "        Y_pred_real= Y_pred_log.copy()\n",
    "        Y_test_real = Y_test_log.copy()\n",
    "    \n",
    "    \n",
    "    # Calcular el MAE real\n",
    "    mae_real = mean_absolute_error(Y_test_real, Y_pred_real)\n",
    "    \n",
    "    print(f\"\\nEl Error Absoluto Medio (MAE) final es de: {mae_real:,.2f} [Moneda]\")\n",
    "    \n",
    "    #  Calcular el Error Cuadrático Medio (MSE)\n",
    "    mse_real = mean_squared_error(Y_test_real, Y_pred_real)\n",
    "    \n",
    "    # Calcular la Raíz del Error Cuadrático Medio (RMSE)\n",
    "    #    La RMSE es simplemente la raíz cuadrada del MSE\n",
    "    rmse_real = np.sqrt(mse_real)\n",
    "    \n",
    "    print(f\"\\nLa Raíz del Error Cuadrático Medio (RMSE) final es de: {rmse_real:,.2f} [Moneda]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98794efb-ecd3-4714-80c7-e18bbc13ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bandera = GetFlag(FrameN['VENTA'])\n",
    "X_processed, Y_log = GetTrainingForm(FrameN.copy(),Bandera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f2af9-8c89-44a2-becc-4120eb0a97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= TrainingNet(X_processed,Y_log)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a27052e-a41d-4320-b29f-24d6525ebf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataForecasting(df,FrameN):\n",
    "\n",
    "    df['TIPO_CLASE'] = np.where(\n",
    "        df['CLASE_SERVICIO'].astype(str).str.contains('DOS PISOS', case=False, na=False),\n",
    "        'DOS',\n",
    "        'UNO'\n",
    "    )\n",
    "    df[\"HORA_SALIDA_CORRIDA\"] = pd.to_datetime(df[\"HORA_SALIDA_CORRIDA\"])\n",
    "    df['FECHA_CORRIDA'] = pd.to_datetime(df['FECHA_CORRIDA'])\n",
    "    df_total = pd.DataFrame(columns=FrameN.columns)\n",
    "    print(df_total.shape)\n",
    "    \n",
    "    df_total['Origen-Destino'] = df['ORIGEN'].astype(str) + '-' + df['DESTINO'].astype(str)\n",
    "    df_total['DiaSemana_Corrida']=df['FECHA_CORRIDA'].dt.dayofweek\n",
    "    df_total['Hora_Corrida']=df['HORA_SALIDA_CORRIDA'].dt.hour\n",
    "    df_total[['NUM_ASIENTO','HORAS_ANTICIPACION']]=df[['NUM_ASIENTO','HORAS_ANTICIPACION']].copy()\n",
    "    df_total['%_dif_TBT_Venta']=FrameN['%_dif_TBT_Venta'].mean()\n",
    "    df_total['Mes_Corrida']=df['FECHA_CORRIDA'].dt.month\n",
    "    df_total['Año_Corrida']=df['FECHA_CORRIDA'].dt.year\n",
    "    df_total['Buen_Dia'] = df['FECHA_CORRIDA'].dt.dayofweek.isin([4,5,6,0]).astype(int)\n",
    "    df_total['Buena_Hora'] = df['HORA_SALIDA_CORRIDA'].dt.hour.isin([23,17,18,19,20]).astype(int)\n",
    "    df_total['Buen_Mes'] = df['FECHA_CORRIDA'].dt.month.isin([3,4,5,6]).astype(int)\n",
    "    df_total['Buen_Asiento'] = df['NUM_ASIENTO'].isin([1,2,3,4,5,6,7,8,9,10]).astype(int)\n",
    "    # Crea un nuevo DataFrame con las variables dummy (codificación one-hot)\n",
    "    df_dummies = pd.get_dummies(\n",
    "        df['TIPO_CLIENTE'],\n",
    "        prefix='TIPO_CLIENTE', # Prefijo para las nuevas columnas (ej: TIPO_CLIENTE_A)\n",
    "        drop_first=False        # Elimina la primera categoría para evitar multicolinealidad\n",
    "    ).astype(int)\n",
    "\n",
    "    df_total[df_dummies.columns]= df_dummies[df_dummies.columns].copy()\n",
    "    # Crea un nuevo DataFrame con las variables dummy (codificación one-hot)\n",
    "    df_dummies1 = pd.get_dummies(\n",
    "        df['TIPO_CLASE'],\n",
    "        prefix='PISO', \n",
    "        drop_first=False\n",
    "    ).astype(int)\n",
    "\n",
    "    df_total[df_dummies1.columns]= df_dummies1[df_dummies1.columns].copy()\n",
    "    # Une las nuevas columnas dummy al DataFrame original\n",
    "\n",
    "    df_total['VENTA']=df['VENTA'].copy()\n",
    "\n",
    "    #df_total=df_total.fillna(0)\n",
    "    \n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79caab-98ae-456a-906d-30af0e588fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareData4Fore(df):\n",
    "    #df=Get_Data()\n",
    "    # Se filtra el DataFrame para incluir solo ventas mayores que cero.\n",
    "    df = df[df['VENTA'] > 0]\n",
    "    df['FECHA_OPERACION'] = pd.to_datetime(df['FECHA_OPERACION'])\n",
    "    fecha_maxima = df['FECHA_OPERACION'].max()\n",
    "    df = df[df['FECHA_OPERACION'] == fecha_maxima].copy()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1200e-a7ef-41c9-ace0-b242473c8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPredictingForm(Fore,cols):\n",
    "    X1 = Fore.drop('VENTA', axis=1)\n",
    "    \n",
    "    X_final=pd.DataFrame(columns=cols)\n",
    "    \n",
    "    categorical_features= 'Origen-Destino'\n",
    "    df_ohe = pd.get_dummies(X1[categorical_features]).astype(int)\n",
    "    \n",
    "    # Columnas numéricas que necesitan Estandarización\n",
    "    # Excluimos las binarias/dummies que ya están bien escaladas (0 o 1)\n",
    "    numeric_features = [\n",
    "        'DiaSemana_Corrida', 'Hora_Corrida', 'NUM_ASIENTO', \n",
    "        'HORAS_ANTICIPACION', '%_dif_TBT_Venta', 'Mes_Corrida','Año_Corrida'\n",
    "    ]\n",
    "    \n",
    "    # Columnas binarias (se dejan pasar sin transformación)\n",
    "    binary_features = [col for col in X1.columns if col not in [categorical_features] + numeric_features]\n",
    "    \n",
    "    indice_correcto = X1[numeric_features].index # o df_ohe.index\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    # 2. Convierte el array escalado (NumPy) a DataFrame, ASIGNANDO el índice correcto\n",
    "    X_escalado_array = scaler.fit_transform(X1[numeric_features])\n",
    "    X_escalado = pd.DataFrame(X_escalado_array, \n",
    "                              index=indice_correcto, # <-- ¡CLAVE!\n",
    "                              columns=numeric_features)\n",
    "    \n",
    "    X_processed1= pd.concat([df_ohe, X_escalado,X1[binary_features]], axis=1)\n",
    "    \n",
    "    X_final[X_processed1.columns]= X_processed1[X_processed1.columns].copy()\n",
    "    X_final=X_final.fillna(0)\n",
    "\n",
    "    return X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5f494-048b-46ad-ab47-110074ccdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetValues(model,Fore,X_final):\n",
    "    # 'model' es tu red neuronal entrenada\n",
    "    # 'X_test' son tus features de prueba (escalados y codificados)\n",
    "    Y_pred_log = model.predict(X_final)\n",
    "    \n",
    "    Y_R_real = Fore['VENTA']\n",
    "                \n",
    "    if Bandera:\n",
    "        # Revertir la predicción logarítmica a la escala de precio real\n",
    "        Y_pred_real = np.exp(Y_pred_log)\n",
    "    else:\n",
    "        Y_pred_real= Y_pred_log.copy()\n",
    "    \n",
    "    # Calcular el MAE real\n",
    "    mae_real = mean_absolute_error(Y_R_real, Y_pred_real)\n",
    "    \n",
    "    print(f\"\\nEl Error Absoluto Medio (MAE) final es de: {mae_real:,.2f} [Moneda]\")\n",
    "    return Y_pred_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a2e68-d0f6-452a-b2e9-b898b0f74745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_today= PrepareData4Fore(Frame.copy())\n",
    "Fore=DataForecasting(df_today,FrameN)\n",
    "X_final= GetPredictingForm(Fore, X_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a04562-9d68-43a4-83fd-8f49eba1679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GetValues(model,Fore,X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5866c3-0b0f-4c93-9a9f-2c6563309c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dd02d-1702-42ce-8718-b2e0a1ba626d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
